---
layout: posts
title: 动手学AI-基本知识点
date: 2025-10-14 13:59:06
tags: 
 - [AI]
 - [机器学习]
categories: 
 - [学习]
---
# 模型训练
## 过拟合和欠拟合
过拟合就是在训练数据集上训练的“太好”，而不适用于其他的大型真实数据集。
即如果有足够多的神经元、层数和训练迭代周期， 模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。

欠拟合就是训练误差和验证误差都比较大而且二者之间的差距很小，这就代表模型的表达能力不足，仍需要训练一个更复杂的模型。

## 训练误差和泛化误差
训练误差（training error）是指， 模型在训练数据集上计算得到的误差。 泛化误差（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

泛化误差是无法被精确计算出来的，因为无限多数据样本不可能供我们使用，这是一个虚拟的对象，因此只能用一个独立的测试机来估计。

## 模型复杂性
这是一个比较难定义的东西，可能是参数更多的模型更复杂，也可能是迭代更多次的模型更复杂，也会是训练样本的数量越大越复杂。

## 验证集&测试集
二者之间的关系非常模糊，因为理论上我们希望测试集能一下测试完模型的误差，这样就能保证独立同分布，但是在实际操作中，因为模型需要不断迭代，每一轮都要用测试集来更新，因此验证集这个概念就被提出，但是他俩还是很难界定，教程里的准确度都用验证集准确度测定。

## K折交叉验证
把原始训练数据分为K个不重叠的子集，执行K此训练和验证，每次在K-1个子集上进行训练，在剩余的一个子集上验证，最后对K次实验结果取平均来估计误差。

## 权重衰减

